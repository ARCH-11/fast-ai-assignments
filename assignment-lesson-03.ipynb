{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lesson 03 - Under and Over Fitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The previous model which we have used transfer learning for Cats and Dogs Redux Kaggle competition was under fitting. The training accuracy was lower than the validation accuracy. This is due to dropout operations in dense (fully connected) layers in VGG-16 model. We should somehow remove the dropout operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# import the model and utils\n",
    "import numpy as np\n",
    "from utils import *\n",
    "from importlib import reload\n",
    "import vgg16_for_keras2\n",
    "reload(vgg16_for_keras2)\n",
    "from vgg16_for_keras2 import Vgg16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vgg = Vgg16()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\u001b[01;31mdata.zip\u001b[0m               subm_full.csv            \u001b[01;34mtest10\u001b[0m/\r\n",
      "\u001b[01;34msample10-fast-ai\u001b[0m/      subm_sample.csv          \u001b[01;34mtrain\u001b[0m/\r\n",
      "\u001b[01;34msample-fast-ai\u001b[0m/        subm_sample_ordered.csv  \u001b[01;34mtrain-fast-ai\u001b[0m/\r\n",
      "sample_submission.csv  \u001b[01;34mtest\u001b[0m/                    \u001b[01;34mvalid-fast-ai\u001b[0m/\r\n"
     ]
    }
   ],
   "source": [
    "%ls data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path = './data/sample-fast-ai/'\n",
    "batch_size = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\u001b[01;34mtrain\u001b[0m/  \u001b[01;34mvalid\u001b[0m/\r\n"
     ]
    }
   ],
   "source": [
    "%ls data/sample-fast-ai/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.utils.np_utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 200 images belonging to 2 classes.\n",
      "Found 200 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "batches = vgg.get_batches(path+'train', shuffle=True, batch_size=batch_size)\n",
    "val_batches = vgg.get_batches(path+'valid', shuffle=True, batch_size=batch_size)\n",
    "\n",
    "train_labels = to_categorical(batches.classes)\n",
    "val_labels = to_categorical(val_batches.classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# change the output layer from 1000 nodes to 2 nodes\n",
    "vgg.finetune(batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lambda_1 (Lambda)            (None, 3, 224, 224)       0         \n",
      "_________________________________________________________________\n",
      "zero_padding2d_1 (ZeroPaddin (None, 3, 226, 226)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 64, 224, 224)      1792      \n",
      "_________________________________________________________________\n",
      "zero_padding2d_2 (ZeroPaddin (None, 64, 226, 226)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 64, 224, 224)      36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 64, 112, 112)      0         \n",
      "_________________________________________________________________\n",
      "zero_padding2d_3 (ZeroPaddin (None, 64, 114, 114)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 128, 112, 112)     73856     \n",
      "_________________________________________________________________\n",
      "zero_padding2d_4 (ZeroPaddin (None, 128, 114, 114)     0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 128, 112, 112)     147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 128, 56, 56)       0         \n",
      "_________________________________________________________________\n",
      "zero_padding2d_5 (ZeroPaddin (None, 128, 58, 58)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 256, 56, 56)       295168    \n",
      "_________________________________________________________________\n",
      "zero_padding2d_6 (ZeroPaddin (None, 256, 58, 58)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 256, 56, 56)       590080    \n",
      "_________________________________________________________________\n",
      "zero_padding2d_7 (ZeroPaddin (None, 256, 58, 58)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 256, 56, 56)       590080    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 256, 28, 28)       0         \n",
      "_________________________________________________________________\n",
      "zero_padding2d_8 (ZeroPaddin (None, 256, 30, 30)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 512, 28, 28)       1180160   \n",
      "_________________________________________________________________\n",
      "zero_padding2d_9 (ZeroPaddin (None, 512, 30, 30)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 512, 28, 28)       2359808   \n",
      "_________________________________________________________________\n",
      "zero_padding2d_10 (ZeroPaddi (None, 512, 30, 30)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 512, 28, 28)       2359808   \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 512, 14, 14)       0         \n",
      "_________________________________________________________________\n",
      "zero_padding2d_11 (ZeroPaddi (None, 512, 16, 16)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 512, 14, 14)       2359808   \n",
      "_________________________________________________________________\n",
      "zero_padding2d_12 (ZeroPaddi (None, 512, 16, 16)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_12 (Conv2D)           (None, 512, 14, 14)       2359808   \n",
      "_________________________________________________________________\n",
      "zero_padding2d_13 (ZeroPaddi (None, 512, 16, 16)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_13 (Conv2D)           (None, 512, 14, 14)       2359808   \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 512, 7, 7)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 4096)              102764544 \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 4096)              16781312  \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 2)                 8194      \n",
      "=================================================================\n",
      "Total params: 134,268,738.0\n",
      "Trainable params: 8,194.0\n",
      "Non-trainable params: 134,260,544.0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "vgg.model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get layers\n",
    "layers = vgg.model.layers\n",
    "len(layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.layers import Convolution2D\n",
    "from keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'keras.layers.core.Dense'>\n",
      "<class 'keras.layers.core.Dropout'>\n",
      "<class 'keras.layers.core.Dense'>\n",
      "<class 'keras.layers.convolutional.Conv2D'>\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "# lets check the layer types\n",
    "print(type(layers[37]))\n",
    "print(type(layers[36]))\n",
    "print(type(layers[35]))\n",
    "print(type(layers[23]))\n",
    "print(type(layers[23]) is Convolution2D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30\n"
     ]
    }
   ],
   "source": [
    "# find the index of last convolutional layer\n",
    "last_conv_index = [index for index,layer in enumerate(layers)\n",
    "                      if type(layer) is Convolution2D][-1]\n",
    "print(last_conv_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'keras.layers.convolutional.Conv2D'>\n",
      "<class 'keras.layers.pooling.MaxPooling2D'>\n",
      "<class 'keras.layers.core.Flatten'>\n"
     ]
    }
   ],
   "source": [
    "print(type(layers[30]))\n",
    "print(type(layers[31]))\n",
    "print(type(layers[32]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "conv_layers = layers[:last_conv_index+1]\n",
    "conv_model = Sequential(conv_layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fc_layers = layers[last_conv_index+1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "val_features = conv_model.predict_generator(val_batches, val_batches.samples//batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200, 512, 14, 14)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_features = conv_model.predict_generator(batches, batches.samples//batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200, 512, 14, 14)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(train_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import bcolz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#%rm -r bottleneck_features/*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# save bottleneck fetures for later use\n",
    "features_dir ='bottleneck_features'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\u001b[01;34mtrain_features\u001b[0m/  \u001b[01;34mval_features\u001b[0m/\r\n"
     ]
    }
   ],
   "source": [
    "# save\n",
    "%mkdir -p features_dir\n",
    "c = bcolz.carray(val_features, rootdir=features_dir+'/val_features', mode='w')\n",
    "c.flush()\n",
    "\n",
    "c = bcolz.carray(train_features, rootdir=features_dir+'/train_features', mode='w')\n",
    "c.flush()\n",
    "\n",
    "%ls bottleneck_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_features = bcolz.open(features_dir+'/train_features')\n",
    "val_features = bcolz.open(features_dir+'/val_features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200, 512, 14, 14)\n",
      "(200, 512, 14, 14)\n"
     ]
    }
   ],
   "source": [
    "print(train_features.shape)\n",
    "print(val_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.layers import MaxPooling2D, Dense, Flatten, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(None, 512, 14, 14)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv_layers[-1].output_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create fully connected model\n",
    "fc_model = Sequential([\n",
    "    MaxPooling2D(input_shape=conv_layers[-1].output_shape[1:]),\n",
    "    Flatten(),\n",
    "    Dense(4096, activation='relu'),\n",
    "    Dropout(0.),\n",
    "    Dense(4096, activation='relu'),\n",
    "    Dropout(0.),\n",
    "    Dense(2, activation='softmax'),\n",
    "]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_layer_weights(layer): return [o for o in layer.get_weights()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load weights to fc_model\n",
    "for l1,l2 in zip(fc_model.layers, fc_layers): l1.set_weights(get_layer_weights(l2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4096, 4096)\n",
      "(4096,)\n"
     ]
    }
   ],
   "source": [
    "# just a test on how weights are handled\n",
    "w = [o for o in fc_model.layers[4].get_weights()]\n",
    "print(w[0].shape)\n",
    "print(w[1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# compile the model\n",
    "fc_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# train model\n",
    "fc_model.fit(\n",
    "    train_features, train_labels, validation_data=(val_features,val_labels),\n",
    "    batch_size=2, epochs=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I was unabled to give results here. I tried to run the model on an Amazon AWS g2x.large instance, however data is too large to fit in one of these GPUs. Maybe, as a solution, i will implement the same model in TensorFlow to run parallel on all 4 GPUs of g2x.large instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
